{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fb1EaQJiYp_r"
      },
      "outputs": [],
      "source": [
        "#Multi-armed bandit exploration\n",
        "\n",
        "#import statements\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set up all valid parameters\n",
        "#for now we'll be going by the example given in this video:\n",
        "#https://www.youtube.com/watch?v=e3L4VocZnnQ\n",
        "#later on in the code we'll go over solutions for k-armed bandits\n",
        "\n",
        "means = [10, 8, 5]\n",
        "stdevs = [5, 4, 2.5]\n",
        "num_meals = 300\n",
        "optimal = max(means) * num_meals # optimal happiness value on average"
      ],
      "metadata": {
        "id": "J0MJ56I-ZmL5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the first naive strategy: explore only\n",
        "def basic_naive_explore():\n",
        "  happiness = 0\n",
        "\n",
        "  times_per_restaurant = num_meals / len(means)\n",
        "  happiness = [times_per_restaurant * i for i in means]\n",
        "  happiness = sum(happiness)\n",
        "\n",
        "  regret = optimal - happiness\n",
        "  return regret\n",
        "basic_naive_explore()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tPXJLnveEmB",
        "outputId": "4f734224-9b4f-490a-d24e-fc1f4eb56512"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "700.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the second naive strategy: exploit only\n",
        "def basic_naive_exploit():\n",
        "  happiness = 0\n",
        "  num_restaurants = len(means)\n",
        "  samples = [np.random.normal(i, j, 1)[0] for i, j in zip(means, stdevs)]\n",
        "  \n",
        "  exploit_res = samples.index(max(samples))\n",
        "\n",
        "  meals_left = num_meals - num_restaurants\n",
        "\n",
        "  happiness = happiness + sum(samples)\n",
        "\n",
        "  for x in range(meals_left):\n",
        "    happiness = happiness + np.random.normal(means[exploit_res], stdevs[exploit_res], 1)[0]\n",
        "\n",
        "  regret = optimal - happiness\n",
        "  return regret\n",
        "basic_naive_exploit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un0A3lI6hNw4",
        "outputId": "40cb060f-3141-471c-aa00-2203e648409c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "697.7241573114848"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the epsilon greedy strategy\n",
        "epsilon = 10 #we're going for a ten percent chance of exploration\n",
        "\n",
        "def basic_epsilon_greedy():\n",
        "  happiness = 0\n",
        "  samples = [np.random.normal(i, j, 1)[0] for i, j in zip(means, stdevs)]\n",
        "  averages = {}\n",
        "  num_values = {}\n",
        "  for x in range(len(means)):\n",
        "    averages[x] = samples[x]\n",
        "    num_values[x] = 1\n",
        "  \n",
        "  meals_left = num_meals - len(means)\n",
        "  epsilon_preds = np.random.randint(0, epsilon, meals_left) # in one go we have all of our epislons\n",
        "\n",
        "  for eps in epsilon_preds:\n",
        "    if eps == 0:\n",
        "      rand_res = np.random.randint(0, len(means), 1)[0]\n",
        "      res_score = np.random.normal(means[rand_res], stdevs[rand_res], 1)[0]\n",
        "      happiness = happiness + res_score\n",
        "      num_values[rand_res] = num_values[rand_res] + 1\n",
        "      averages[rand_res] = averages[rand_res] + ((res_score + averages[rand_res])/(num_values[rand_res]))\n",
        "    else:\n",
        "      max_average_res = max(averages, key=averages.get)\n",
        "      res_score = np.random.normal(means[max_average_res], stdevs[max_average_res], 1)[0]\n",
        "      happiness = happiness + res_score\n",
        "\n",
        "  regret = optimal - happiness\n",
        "  return regret\n",
        "basic_epsilon_greedy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlcLqGNIiqHx",
        "outputId": "6c4b49a5-e3f6-472e-e660-caad898dbdcb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141.53532193260753"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}